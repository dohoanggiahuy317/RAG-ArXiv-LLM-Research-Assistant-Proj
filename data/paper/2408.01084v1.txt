Adaptive Contrastive Decoding in Retrieval-Augmented Generation for
Handling Noisy Contexts
Youna Kim1, Hyuhng Joon Kim1, Cheonbok Park2, Choonghyun Park1,
Hyunsoo Cho3, Junyeob Kim1, Kang Min Yoo1 2 4, Sang-goo Lee1, Taeuk Kim5
1Seoul National University,2NA VER Cloud,3Ewha Womans University,
4NA VER AI LAB,5Hanyang University
{anna9812, heyjoonkim, pch330, juny116, sglee}@europa.snu.ac.kr
{cbok.park, kangmin.yoo}@navercorp.com, chohyunsoo@ewha.ac.kr
kimtaeuk@hanyang.ac.kr
Abstract
When using large language models (LLMs)
in knowledge-intensive tasks, such as open-
domain question answering, external context
can bridge a gap between external knowledge
and LLM’s parametric knowledge. Recent re-
search has been developed to amplify con-
textual knowledge over the parametric knowl-
edge of LLM with contrastive decoding ap-
proaches. While these approaches could yield
truthful responses when relevant context is pro-
vided, they are prone to vulnerabilities when
faced with noisy contexts. We extend the scope
of previous studies to encompass noisy con-
texts and propose adaptive contrastive decod-
ing (ACD) to leverage contextual influence ef-
fectively. ACD demonstrates improvements in
open-domain question answering tasks com-
pared to baselines, especially in robustness by
remaining undistracted by noisy contexts in
retrieval-augmented generation.
1 Introduction
While large language models (LLMs) (Touvron
et al., 2023; Achiam et al., 2023) achieve re-
markable performance levels across diverse bench-
marks, they sometimes struggle to generalize to
knowledge-intensive tasks such as open-domain
question-answering (QA; Chen et al., 2017) and
may also fail to capture long-tail knowledge, lead-
ing to unfaithful output generation (Mallen et al.,
2023; Kandpal et al., 2023). One common approach
to address these issues is fine-tuning the model, but
this results in a quadratic rise in computational
demands as the size of the LLMs increases expo-
nentially (Longpre et al., 2023). To address these
issues, researchers have been investigating strate-
gies to combine non-parametric knowledge with
LLMs during response generation without explicit
re-training. This approach leverages external infor-
mation from knowledge bases and enhances the
capability of the LLMs dynamically, ensuring that
the information is both current and accurate.Early studies in this field attempt to append rel-
evant context information to generate more accu-
rate responses (Asai et al., 2023a). Especially, con-
trastive decoding (Li et al., 2023; Malkin et al.,
2022; Liu et al., 2021) yields significant enhance-
ment in various tasks by amplifying the influence
of the given context at decoding step (Shi et al.,
2023; Zhao et al., 2024). While such methods work
well when context information is correct and faith-
ful, in real-world scenarios, context information
is not always correct and may contain some noisy
and unfaithful information. For instance, if the re-
trieval system pulls in irrelevant or contradictory
information, it could lead to incorrect responses
(Wang et al., 2024; Wu et al., 2024; Yu et al., 2024).
This highlights the necessity for a generation model
that can gauge the appropriateness of the context
by itself, being robust to noise and unfaithful data
to ensure the output remains reliable (Yoran et al.,
2024).
To assess whether the existing contrastive de-
coding approaches can be utilized in practice, we
extend the setting to where the gold-standard con-
text is not guaranteed, specifically in the retrieval-
augmented generation (RAG) framework (Yao
et al., 2022; Shi et al., 2024; Izacard et al., 2023).
In this paper, we demonstrate that existing context-
aware contrastive decoding approaches experience
performance drops in open-domain question an-
swering, especially when the retrieved context is
noisy. To address this issue, we propose adaptive
contrastive decoding (ACD) , adaptively weight-
ing the contrastive contextual influence on the para-

noisy. To address this issue, we propose adaptive
contrastive decoding (ACD) , adaptively weight-
ing the contrastive contextual influence on the para-
metric knowledge, making it suitable for noisy con-
text settings.
Incorporating the distinction between contextual
and parametric knowledge, our approach aims to
mitigate the dominance of potentially noisy contex-
tual information in model output. We control con-
trastive contextual influence based on context’s con-
tribution to LLM’s uncertainty reduction, thereby
1arXiv:2408.01084v1  [cs.CL]  2 Aug 2024

minimizing its disruptive effect during decoding.
Through in-depth experiments with three open-
domain QA datasets, we demonstrate the potential
of the proposed approach with increased overall
performance. Moreover, ACD enhances the perfor-
mance significantly on the noisy context scenario
while minimizing performance degradation on the
gold context scenario compared to the baselines.
2 Methodology
2.1 Problem Formulation
At decoding time step t, given the input xand pre-
ceding sequences y<t, a pretrained auto-regressive
LLM θcomputes the logit zt∈R|V|, where V
is the vocabulary, for the t-th token. In the open-
domain QA task, a question qserves as the input
x, and ztrelies solely on LM’s parametric knowl-
edge. When both qand the retrieved context care
provided as x, the logit is denoted as zc
t∈R|V|.
2.2 Contrastive Decoding
In cases where context cannot be blindly trusted,
directly following the context-augmented distribu-
tion can increase the risk of being misled. Thus, we
adopt the approach of adding the contextual influ-
ence, which contrasts with the LLM’s parametric
knowledge, to the parametric distribution zt. With
the contrastive decoding objective, zc
tandztare en-
sembled to reflect the influence of external context
on LLM’s parametric knowledge at each decoding
stept. The probability distribution Pθ(Yt|x, y<t)
is modified by weighted adjustment based on the
difference between zc
tandzt, as represented in the
following equation.
Pθ(Yt|x, y<t) =softmax (zt+α(zc
t−zt))(1)
The contrastive adjustment enables the LLM to in-
tegrate external context cinto its prediction, lever-
aging the weight αto control the impact of con
the final probability distribution.
2.3 Adaptive Weight on Contextual Influence
The degree to which contextual influence is incor-
porated into ztneeds to be controlled based on
the provided context’s informativeness. In practice,
however, it is often unknown whether the context
is gold or noisy. To address this, we investigate
whether the model could adjust accordingly with a
simple entropy-based approach.
LLM’s uncertainty is expressed with the entropy
H(Yt)on its probability distribution Pθ(Yt|x, y<t)(Huang et al., 2023; Kuhn et al., 2023). While
H(Yt)reflects how much uncertainty the model
has based on its parametric knowledge under the
given question, H(Yc
t)is influenced by the external
knowledge within the retrieved context c. Gener-
ally, when the context is added, the entropy de-
creases. However, if the context is noisy, irrelevant,
or provides no information to answer the given
question, it may contribute to increased uncertainty
instead.
Intuitively, if the retrieved context provides in-
formative cues for answering the question, then
H(Yc
t)is expected to be lowered compared to
H(Yt). Conversely, if the context is non-helpful
or even confusing the model prediction, H(Yc
t)in
predicting the next token is likely to be higher. This
scenario would be particularly evident when LLM
knows the answer with low H(Yt).
Considering the above scenarios, the motivation
behind the adaptive weight αACD is to assign a
relatively smaller weight in cases where the context
increases uncertainty by being uninformative or
confusing for LLM in answering the given question.
Thus, the value of αACD is set as the proportion
of uncertainty contributed by H(Yt)relative to the
total uncertainty when considering both H(Yt)and
H(Yc
t):
αACD=H(Yt)
H(Yt) +H(Yc
t)(2)
Under the condition where H(Yt)> H (Yc
t),
αACD value approaches to 1, indicating that when
the context cis provided, the uncertainty associ-
ated with predicting the next token decreases. Con-
versely, when H(Yt)< H(Yc
t),αACD value ap-
proaches to 0, reflecting minimal influence from c.
Note that when H(Yt) =H(Yc
t),αACD becomes
0.5, resulting in an ensemble of two distributions,
ztandzc
t, with equal weighting.
With αACD, the full ACD is obtained, and the
vocab vwith maximum probability is selected as
the next token under the following distribution:

ztandzc
t, with equal weighting.
With αACD, the full ACD is obtained, and the
vocab vwith maximum probability is selected as
the next token under the following distribution:
ˆPθ(Yt|x, y<t) =softmax (zt+αACD(zc
t−zt))
(3)
Informed by αACD and contextual contrast, the
adjustment process determines the degree to which
the model’s parametric knowledge is superseded,
thus optimizing the assimilation of contextual in-
formation throughout decoding.
2

Dataset ( →) TriviaQA NQ PopQA
Model Method ( ↓) All Subset Gold Subset Noisy All Subset Gold Subset Noisy All Subset Gold Subset Noisy
LLAMA 2 7BRegCls 59.00 - - 25.48 - - 28.36 - -
RegOpn 60.23 87.40 33.50 31.39 61.31 12.40 38.49 81.21 7.77
CAD 49.02 73.69 24.75 25.57 51.61 9.05 33.70 72.18 6.03
MICD F 60.36 85.72 35.39 29.45 56.10 12.54 35.73 74.25 8.03
MICD D 63.23 86.03 40.79 30.36 52.18 16.52 39.01 77.39 11.42
ACD 64.85 88.01 42.06 32.91 56.60 17.88 41.29 82.77 11.46
LLAMA 2 13BRegCls 63.77 - - 30.80 - - 32.70 - -
RegOpn 62.81 88.52 37.51 33.35 62.96 14.58 40.03 83.20 8.98
CAD 52.62 76.78 28.85 27.87 55.96 10.05 35.86 76.38 6.71
MICD F 63.53 87.40 40.04 32.63 59.67 15.48 38.16 77.04 10.21
MICD D 66.52 87.68 45.69 34.38 57.32 19.83 41.65 79.27 14.60
ACD 67.37 89.36 45.74 36.12 61.17 20.24 43.35 83.98 14.14
Table 1: EM accuracy of full data (All) and subsets with gold (Subset Gold) and noisy contexts (Subset Noisy).
3 Experimental Results
3.1 Experimental Settings
Datasets and Models We conduct experiments
on open-domain QA datasets, TriviaQA (Joshi
et al., 2017), Natural Questions (NQ; Kwiatkowski
et al., 2019), and PopQA (Mallen et al., 2022) with
Wikipedia contexts1.
We use auto-regressive language models,
LLAMA 2(7B & 13B, Touvron et al., 2023),
LLAMA 3 8B2, and MISTRAL 7B(Jiang et al.,
2023). Utilizing CONTRIEVER -MSMARCO (Izac-
ard et al., 2022) as a retriever, the top-1 retrieved
context is appended to each question.
Evaluation Metric Following Zhao et al. (2024),
we use few-shot prompts with 5 examples. We re-
port Exact Match (EM) as an evaluation metric,
which verifies whether the generated sequences
precisely match one of the candidate answers.
Baselines As fundamental baselines, regular
greedy decoding has been employed in open-book
(RegOpn) and closed-book ( RegCls) settings. We
compare our method against existing context-aware
contrastive decoding methods, including Context-
Aware Decoding (CAD; Shi et al., 2023) and Multi-
Input Contrastive Decoding (MICD; Zhao et al.,
2024). MICD presents two methods, referred to
as MICD Fand MICD D, which offer fixed and dy-
namic α, respectively. Similar to our approach, to
leverage the burden of hyperparameter search and
dependency on fixed α, MICD Ddetermines αin
use by comparing the highest token probabilities
with and without given context.
Other implementation details can be found in
Appendix B.
1Wikipedia dump from Dec. 2018.
2https://github.com/meta-llama/llama3
RegOpn CAD MICDFMICDD ACD
Models01020304050607080EM63.46
57.4155.54
48.4755.51
48.91
34.7053.4271.7673.36Unknown-gold Known-noisyFigure 1: EM accuracy of each method in LLAMA 2-7B .
EM of three datasets used are averaged for each subset,
Unknown-gold andKnown-noisy .
3.2 Main Results
Performance on RAG As shown in Table 1,
ACD outperforms the baselines across all datasets
and models, especially considering the full test data
(All). Similar trends in performance are observed
forLLAMA 3 8B andMISTRAL 7B, as detailed
in Appendix C. When analyzing the performance
by dividing the data into two subsets based on
whether the retrieved context is gold ( Subset Gold)
or not ( Subset Noisy), ACD achieves either the best
or second-best performance. MICD Ddemonstrates
performance comparable to ACD on Subset Noisy.
However, it shows a significant drop on Subset Gold,
indicating a tendency to ignore gold context while
handling noisy context. It is notable that both CAD
andMICD Fexhibit a significant drop in their per-
formance under noisy conditions.
Performance under Parametric Knowledge
We aim to analyze the model’s performance across
various aspects, focusing specifically on its para-
metric knowledge. We estimate whether the model
possesses relevant parametric knowledge for a
given question based on its accuracy when only
the question is provided. We consider two subsets
under the following conditions: (1) Known-noisy :
3

α NQ TriviaQA PopQA
MaxMICD D 51.53 59.76 65.49
ACD 65.78 73.37 74.84
Avg.MICD D 54.18 63.78 72.64
ACD 68.80 72.32 78.90
FirstMICD D 53.92 62.95 68.81
ACD 73.27 80.45 80.08
Table 2: AUROC between αused in each method and
the noisiness of the retrieved context.
the model has parametric knowledge and noisy con-
text is retrieved. (2) Unknown-gold : the model does
not have parametric knowledge and gold context is
retrieved.
From Figure 1, we observe that ACD out-
performs the baselines in Known-noisy . Notably,
two approaches with adaptively adjusted weight,
ACD and MICD D, perform well in Known-noisy ,
while other baselines show a relative strength in
Unknown-gold . However, these baselines also ex-
perience significant performance drops in Known-
noisy , indicating distraction by noisy context de-
spite correctly answering when only the question is
provided. In both cases, ACD demonstrates better
performance compared to MICD D, overall show-
ing a tendency towards reliability. The results from
other models are in Appendix D.
3.3 Analysis
Correlation between Adaptive Weight and Con-
text Noisiness While other baselines rely on
the fixed hyperparameter of weight α, ACD and
MICD Dadjust αduring the decoding step. It de-
pends not only on the noisiness of the retrieved
context but also on whether the model’s parametric
knowledge contains an answer to the given ques-
tion. To exclude cases that are not directly related
to the analysis of how weight is adjusted based on
context quality, we use the same subsets, Known-
noisy andUnknown-gold .
Adaptive weights αACDandαMICD are extracted
at each decoding step and analyzed across three
metrics: maximum, average, and the first within
the sequence. As a metric, AUROC between αand
the noisiness of the retrieved context is measured.
AUROC of each αforLLAMA 2-7B is reported in
Table 2, whereas for other models, it can be found
in Appendix E. Under every metric and dataset,
ACD demonstrates a higher AUROC compared
to MICD D. Aligned with our motivation, when
0.00 0.25 0.50 0.75 1.0026283032EM
NQ
0.00 0.25 0.50 0.75 1.00
alpha5859606162636465
TriviaQA
0.00 0.25 0.50 0.75 1.002830323436384042
TriviaQA
ACDFigure 2: EM score vs. alpha values range from 0.0 to
1.0. Dashed line shows the performance with αACD .
the model is knowledgeable and presented with
noisy context, αACDtends to be lower, emphasiz-
ing greater reliance on parametric knowledge. Con-
versely, when the model lacks knowledge and is
provided with gold context, αACD is adjusted to
prioritize reliance on the provided context.
Ablation on αACD To assess whether adaptively
modified αACD contributes performance improve-
ment, we fix the value of αwithin a range [0,1]
and test on datasets used in the main experiment.
In Figure 2, it can be observed that using a fixed α
results in degraded performance compared to ACD.
Increasing the value of alpha, which enhances the
contextual influence on the output distribution, ini-
tially leads to a rise in the EM score. However,
beyond a certain point, further increasing alpha re-
sults in a decline in the EM score. In scenarios with
potential noisy context, a fixed alpha value may not
ensure optimal performance. Therefore, employing
an adaptive weight, αACD , to adjust the impact of
contextual knowledge based on entropy is crucial
for improving overall performance.
As an additional analysis, we provide a case
study of ACD to show how the value of entropy
contributes to adjust αACD and further examine
ACD on knowledge flipping task in Appendix F
and Appendix G.
4 Conclusion
In this work, we mainly tackle handling noisy con-
texts in open-domain QA on the RAG framework.
This method dynamically adjusts contextual influ-
ence during decoding by quantifying uncertainty
dropped by the retrieved context. Our results show
that ACD improves performances across various di-
mensions by considering LLM’s parametric knowl-
edge and context noisiness. These findings high-

dropped by the retrieved context. Our results show
that ACD improves performances across various di-
mensions by considering LLM’s parametric knowl-
edge and context noisiness. These findings high-
light ACD’s potential to enhance the reliability of
retrieval-augmented LLMs.
4

Limitations
Similar to other contrastive decoding approaches,
the inference cost of our approach is higher than the
conventional greedy decoding. Specifically, while
CAD incurs twice the inference cost and MICD
incurs three times the cost, ACD also incurs twice
the inference cost of conventional greedy decoding.
Our research is limited the base models and does
not encompass chat or instruction-following mod-
els trained with reinforcement learning from hu-
man feedback (RLHF) or instruction fine-tuning
(Ouyang et al., 2022; Chung et al., 2022). These
aligned models often generate token distributions
that vary significantly based on the presence or ab-
sence of contextual instruction or templates. For in-
stance, an instruction-following model might start
its generation with "According to the given con-
text ..." when context is provided, while directly
generating the answer in absence of context. This
alignment with the provided instructions poses an-
other challenge to be tackled when the contrastive
decoding approach is utilized.
Our current focus is primarily on short-form QA
tasks. Expanding to QA tasks with long-form gen-
eration will enable a wider range of applications.
Under long-form QA tasks, our approach can be
further developed to investigate scenarios where the
context is only partially relevant to the question.
References
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
Ahmad, Ilge Akkaya, Florencia Leoni Aleman,
Diogo Almeida, Janko Altenschmidt, Sam Altman,
Shyamal Anadkat, et al. 2023. Gpt-4 technical report.
arXiv preprint arXiv:2303.08774 .
Akari Asai, Sewon Min, Zexuan Zhong, and Danqi
Chen. 2023a. Retrieval-based language models and
applications. In Proceedings of the 61st Annual Meet-
ing of the Association for Computational Linguistics
(Volume 6: Tutorial Abstracts) , pages 41–46, Toronto,
Canada. Association for Computational Linguistics.
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and
Hannaneh Hajishirzi. 2023b. Self-rag: Learning to
retrieve, generate, and critique through self-reflection.
Preprint , arXiv:2310.11511.
Danqi Chen, Adam Fisch, Jason Weston, and Antoine
Bordes. 2017. Reading Wikipedia to answer open-
domain questions. In Proceedings of the 55th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers) , pages 1870–1879,
Vancouver, Canada. Association for Computational
Linguistics.Hyung Won Chung, Le Hou, Shayne Longpre, Barret
Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Al-
bert Webson, Shixiang Shane Gu, Zhuyun Dai,
Mirac Suzgun, Xinyun Chen, Aakanksha Chowdh-
ery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,
Dasha Valter, Sharan Narang, Gaurav Mishra, Adams
Yu, Vincent Zhao, Yanping Huang, Andrew Dai,
Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-
cob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le,
and Jason Wei. 2022. Scaling instruction-finetuned
language models. Preprint , arXiv:2210.11416.
Zhenyu He, Zexuan Zhong, Tianle Cai, Jason D. Lee,
and Di He. 2024. Rest: Retrieval-based speculative
decoding. Preprint , arXiv:2311.08252.
Giwon Hong, Aryo Pradipta Gema, Rohit Saxena,
Xiaotang Du, Ping Nie, Yu Zhao, Laura Perez-
Beltrachini, Max Ryabinin, Xuanli He, Clémentine
Fourrier, and Pasquale Minervini. 2024. The hallu-
cinations leaderboard – an open effort to measure
hallucinations in large language models. Preprint ,
arXiv:2404.05904.
Yuheng Huang, Jiayang Song, Zhijie Wang, Shengming
Zhao, Huaming Chen, Felix Juefei-Xu, and Lei Ma.
2023. Look before you leap: An exploratory study of
uncertainty measurement for large language models.
Preprint , arXiv:2307.10236.
Gautier Izacard, Mathilde Caron, Lucas Hosseini, Se-
bastian Riedel, Piotr Bojanowski, Armand Joulin,
and Edouard Grave. 2022. Unsupervised dense infor-
mation retrieval with contrastive learning. Preprint ,
arXiv:2112.09118.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas
Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-

mation retrieval with contrastive learning. Preprint ,
arXiv:2112.09118.
Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas
Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-
Yu, Armand Joulin, Sebastian Riedel, and Edouard
Grave. 2023. Atlas: Few-shot learning with retrieval
augmented language models. Journal of Machine
Learning Research , 24(251):1–43.
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-
sch, Chris Bamford, Devendra Singh Chaplot, Diego
de las Casas, Florian Bressand, Gianna Lengyel, Guil-
laume Lample, Lucile Saulnier, Lélio Renard Lavaud,
Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,
Thibaut Lavril, Thomas Wang, Timothée Lacroix,
and William El Sayed. 2023. Mistral 7b. Preprint ,
arXiv:2310.06825.
Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke
Zettlemoyer. 2017. Triviaqa: A large scale distantly
supervised challenge dataset for reading comprehen-
sion. Preprint , arXiv:1705.03551.
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric
Wallace, and Colin Raffel. 2023. Large language
models struggle to learn long-tail knowledge. In
Proceedings of the 40th International Conference
on Machine Learning , volume 202 of Proceedings
of Machine Learning Research , pages 15696–15707.
PMLR.
5

Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2023.
Semantic uncertainty: Linguistic invariances for un-
certainty estimation in natural language generation.
Preprint , arXiv:2302.09664.
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-
field, Michael Collins, Ankur Parikh, Chris Alberti,
Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-
ton Lee, et al. 2019. Natural questions: a benchmark
for question answering research. Transactions of the
Association for Computational Linguistics , 7:453–
466.
Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang,
Jason Eisner, Tatsunori Hashimoto, Luke Zettle-
moyer, and Mike Lewis. 2023. Contrastive decod-
ing: Open-ended text generation as optimization. In
Proceedings of the 61st Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers) , pages 12286–12312, Toronto, Canada.
Association for Computational Linguistics.
Alisa Liu, Maarten Sap, Ximing Lu, Swabha
Swayamdipta, Chandra Bhagavatula, Noah A. Smith,
and Yejin Choi. 2021. DExperts: Decoding-time con-
trolled text generation with experts and anti-experts.
InProceedings of the 59th Annual Meeting of the
Association for Computational Linguistics and the
11th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers) , pages
6691–6706, Online. Association for Computational
Linguistics.
Shayne Longpre, Kartik Perisetla, Anthony Chen,
Nikhil Ramesh, Chris DuBois, and Sameer Singh.
2022. Entity-based knowledge conflicts in question
answering. Preprint , arXiv:2109.05052.
Shayne Longpre, Gregory Yauney, Emily Reif, Kather-
ine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Ja-
son Wei, Kevin Robinson, David Mimno, and Daphne
Ippolito. 2023. A pretrainer’s guide to training data:
Measuring the effects of data age, domain coverage,
quality, & toxicity. Preprint , arXiv:2305.13169.
Nikolay Malkin, Zhen Wang, and Nebojsa Jojic. 2022.
Coherence boosting: When your pretrained language
model is not paying enough attention. In Proceedings
of the 60th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers) ,
pages 8214–8236, Dublin, Ireland. Association for
Computational Linguistics.
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2022.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. arXiv preprint arXiv:2212.10511 .
Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das,
Daniel Khashabi, and Hannaneh Hajishirzi. 2023.
When not to trust language models: Investigating
effectiveness of parametric and non-parametric mem-
ories. In Proceedings of the 61st Annual Meeting ofthe Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 9802–9822, Toronto,
Canada. Association for Computational Linguistics.
Shashi Narayan, Shay B. Cohen, and Mirella Lapata.
2018. Don’t give me the details, just the summary!
topic-aware convolutional neural networks for ex-
treme summarization. In Proceedings of the 2018
Conference on Empirical Methods in Natural Lan-
guage Processing , pages 1797–1807, Brussels, Bel-
gium. Association for Computational Linguistics.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. Preprint , arXiv:2203.02155.
Abigail See, Peter J. Liu, and Christopher D. Manning.
2017. Get to the point: Summarization with pointer-
generator networks. Preprint , arXiv:1704.04368.
Weijia Shi, Xiaochuang Han, Mike Lewis, Yulia
Tsvetkov, Luke Zettlemoyer, and Scott Wen tau
Yih. 2023. Trusting your evidence: Halluci-
nate less with context-aware decoding. Preprint ,
arXiv:2305.14739.
Weijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou,

Yih. 2023. Trusting your evidence: Halluci-
nate less with context-aware decoding. Preprint ,
arXiv:2305.14739.
Weijia Shi, Sewon Min, Maria Lomeli, Chunting Zhou,
Margaret Li, Gergely Szilvasy, Rich James, Xi Vic-
toria Lin, Noah A. Smith, Luke Zettlemoyer, Scott
Yih, and Mike Lewis. 2024. In-context pretraining:
Language modeling beyond document boundaries.
Preprint , arXiv:2310.10638.
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurelien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023. Llama 2: Open foundation and fine-
tuned chat models. Preprint , arXiv:2307.09288.
Yuhao Wang, Ruiyang Ren, Junyi Li, Wayne Xin
Zhao, Jing Liu, and Ji-Rong Wen. 2024. Rear:
A relevance-aware retrieval-augmented framework
6

for open-domain question answering. Preprint ,
arXiv:2402.17497.
Siye Wu, Jian Xie, Jiangjie Chen, Tinghui Zhu, Kai
Zhang, and Yanghua Xiao. 2024. How easily do
irrelevant inputs skew the responses of large language
models? Preprint , arXiv:2404.03302.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik Narasimhan, and Yuan Cao. 2022.
React: Synergizing reasoning and acting in language
models. arXiv preprint arXiv:2210.03629 .
Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan
Berant. 2024. Making retrieval-augmented lan-
guage models robust to irrelevant context. Preprint ,
arXiv:2310.01558.
Tian Yu, Shaolei Zhang, and Yang Feng. 2024. Truth-
aware context selection: Mitigating hallucinations of
large language models being misled by untruthful
contexts. Preprint , arXiv:2403.07556.
Zihan Zhang, Meng Fang, and Ling Chen. 2024. Re-
trievalqa: Assessing adaptive retrieval-augmented
generation for short-form open-domain question an-
swering. Preprint , arXiv:2402.16457.
Zheng Zhao, Emilio Monti, Jens Lehmann, and
Haytham Assem. 2024. Enhancing contextual un-
derstanding in large language models through con-
trastive decoding. Preprint , arXiv:2405.02750.
Wenxuan Zhou, Sheng Zhang, Hoifung Poon, and
Muhao Chen. 2023. Context-faithful prompting
for large language models. In Findings of the As-
sociation for Computational Linguistics: EMNLP
2023 , pages 14544–14556, Singapore. Association
for Computational Linguistics.
A Related Works
Context-augmented Generation With the ob-
jective of closely adhering to the context provided,
context-augmented generation strategies have been
developed to better utilize the context and produce
more factual and context-relevant responses at the
inference time (Zhou et al., 2023; He et al., 2024).
Especially, approaches integrated with contrastive
decoding (Li et al., 2023; Malkin et al., 2022; Liu
et al., 2021) yield significant enhancement by am-
plifying the influence of the given context at de-
coding step (Shi et al., 2023; Zhao et al., 2024).
These context-aware contrastive decoding methods
to generate responses faithful to the given context
show effective performance in summarization (See
et al., 2017; Narayan et al., 2018), knowledge flip-
ping (Longpre et al., 2022), and question answering
with gold-standard contexts.Answer the following questions:
<few-shots>
Question: <question>
Answer:
Table 3: Template used in closed-book generation.
Answer the following questions:
<few-shots>
Context: <context>
Question: <question>
Answer:
Table 4: Template used in open-book generation.
Robustness in RAG Framework While
retrieval-augmented generation enables LLMs
to become factual and reliable with the retrieved
external knowledge, there are still concerns about
incorrectly retrieved irrelevant contexts (Yoran
et al., 2024). To address hallucination errors posed
by irrelevant contexts, some researchers take an
approach to train LLMs that can adaptively retrieve
relevant context (Asai et al., 2023b; Wang et al.,
2024). Another approach aims to selectively use
retrieved contexts after assessing their truthfulness
or relevance through context verification with
prompting strategies or training untruthful context
detectors (Yu et al., 2024; Zhang et al., 2024).
These approaches highlight the ongoing efforts
to advance the robustness and accuracy of LLMs
in multiple directions to manage potentially
misleading information.
B Implementation Details
B.1 Instructions
The templates we use throughout the experiment
are in Table 3 and Table 4. The template used in
open-book generation (Table 4) is applied to get
context-augmented distribution zc
t. Also, to obtain
zt, the template in Table 3 is used.
B.2 Datasets
For NQ and TriviaQA, general world knowledge is
required to answer the given question. In PopQA,
tackling long-tailed information, less popular fac-
tual knowledge is asked. For NQ and TriviaQA,
7

R@1 R@5 R@10 R@20 R@100
NQ 38.81 65.65 73.91 79.56 88.01
TriviaQA 49.60 71.32 76.72 80.39 85.71
PopQA 41.83 61.54 68.63 74.55 83.95
Table 5: Recall@100 performance for CONTRIEVER -
MSMARCO
few-shot examples are adopted from train data. For
PopQA, we randomly sample 5 examples with dif-
ferent relationship types for sample diversity. The
number of test data in used is 3,610 for NQ, 11,313
for TriviaQA, and 14,262 for PopQA.
B.3 Baselines
CAD introduces a context-aware contrastive de-
coding approach that employs a contrastive out-
put distribution to accentuate discrepancies in
model predictions with and without context. This
method effectively overrides model priors conflict-
ing with provided context, offering significant per-
formance enhancements in tasks requiring reso-
lution of knowledge conflicts. MICD further en-
hances context grounded generation by integrat-
ing contrastive decoding with adversarial irrelevant
passages.
From a computational time perspective, MICD
requires three times more than conventional greedy
decoding, while CAD and ACD require twice as
much.
MICD proposes two usage directions, referred
to as MICD Fand MICD D, which offer fixed and
dynamic α, respectively. In MICD D,αis assigned
as the maximum token probability with context
(maxP wc) ifmaxP wcexceeds the maximum token
probability without context ( maxP woc); otherwise,
it is calculated as 1−maxP woc.
Throughout the experiments, fixed value of αis
set to the value used in Zhao et al. (2024), 0.5 and
1.0 for CAD and MICD F, respectively.
B.4 Retriever Performance
To assess performance in the RAG framework, the
top-1 context from top-100 contexts retrieved by
CONTRIEVER -MSMARCO (Izacard et al., 2022) is
utilized. Recall@100 is reported for each dataset
in Table 5.
C Main Results on Llama3 and Mistral
Main results on LLAMA 3 8B andMISTRAL 7B
are reported in Table 7.
Llama2-7B Llama2-13B Llama3-8B Mistral-7B
Models020406080EMRegClsMICDD ACD RegOpnFigure 3: EM accuracy on NQ-swap with contexts re-
placing the gold answer with a random entity span.
D Full Results on Known-noisy and
Unknown-gold
ForKnown-noisy andUnknown-gold , the exact val-
ues of EM accuracy on each case are reported in
Table 8 and Table 9, respectively.
E AUROC between αand Context
Noisiness
AUROC of ACD and MICD Dfor three models not
reported in Table 1 is reported in Table 10.
F Case Study on αACD
We conduct the case study on αACD, examining
its value in cases of Known-noisy andUnknown-
gold. Table 6 shows the generations from LLAMA 2
7Band how the values of entropy from closed-
book generation ( RegCls) and open-book genera-
tion ( RegOpn) affect αACD at the first decoding
time step.
In case of Known-noisy , when the model gener-
ates the answer correctly even without the given
context, the retrieved noisy context yields relatively
higher entropy, resulting in αACD value of 0.3483.
Conversely, in the case of Unknown-gold , the
model’s generated answer is incorrect, aligning
with a relatively high entropy value of 6.6748. In
this scenario, the retrieved gold context guides the
model to correctly answer the question, which is re-
flected in a relatively lower entropy value of 1.5628.
Thus, the value of αACD, adjusted with these en-
tropy values, yields a relatively higher weight on
the context at 0.8103.
G Knowledge Conflict
In case where the provided context is different from
what the model knows but relevant to the question,
we verify whether the two decoding methods with
dynamic weight, ACD and MICD D, can generate
responses without considering it as a noisy context
with NQ-Swap dataset (Longpre et al., 2022).
8

Sample RegCls RegOpn ACD
Case Generation H(Yt) Generation H(Yc
t) Generation αACD
Known-noisy Question: who does the voice
Moira Kelly 2.9160 Whoopi Goldberg 5.4562 Moira Kelly 0.3483 of nala in the lion king?
Gold answer: Moira Kelly
Unknown-gold Question: who was the actor that
Michael Tucker 6.6748 Michael Moriarty 1.5628 Michael Moriarty 0.8103 played ben stone on law and order?
Gold answer: Michael Moriarty
Table 6: Case study on the value of αACD forKnown-noisy andUnknown-gold cases in L LAMA 2 7B. Each value
of entropy without context ( H(Yt)), entropy with context ( H(Yc
t)), and αACD is extracted at the first decoding step
(t= 0).
NQ-swap (Longpre et al., 2022) is constructed
by replacing the answer entity span in the original
gold context of NQ questions with a random entity,
to verify if the knowledge is successfully flipped.
We use the questions and swapped contexts pro-
vided in Hong et al. (2024) with 3650 samples
excluding 5 examples used as few-shot prompts
and samples with the context in a tabular format
due to the limited context length. In the case of NQ-
SWAP, each data point has a given context. Since
it is a task that does not use a retriever, for MICD,
we use the fixed negative context taken from the
MICD as an adversarial context. MICD reports that
the performance difference between fixed negative
and the most-distant context is negligible.
Figure 3 illustrates that ACD consistently ex-
ceeds the performance of MICD Dacross all mod-
els and achieves results comparable to open-book
regular decoding. The results indicate that the
ACD’s approach remains effective even in settings
where the context is relevant to the question but
contradicts the parametric knowledge.
9

Datasets ( →) TriviaQA NQ PopQA
Methods ( ↓) All Subset Gold Subset Noisy All Subset Gold Subset Noisy All Subset Gold Subset Noisy
LLAMA 3 8B
RegCls 61.67 - - 28.34 - - 32.65 - -
RegOpn 61.27 86.94 36.02 33.30 63.10 14.40 39.73 82.95 8.64
CAD 49.70 72.45 27.31 29.17 58.39 10.64 35.86 76.82 6.40
MICD F 61.01 85.40 37.00 27.62 51.89 12.22 37.99 77.12 9.85
MICD D 64.01 86.08 42.28 30.72 53.96 15.98 41.35 79.32 14.04
ACD 66.32 89.20 43.81 35.48 62.03 18.65 43.25 84.48 13.60
MISTRAL 7B
RegCls 63.72 - - 29.64 - - 29.04 - -
RegOpn 60.45 86.85 34.48 32.55 64.67 12.18 38.28 81.26 7.36
CAD 44.69 66.89 22.85 24.10 52.25 6.25 33.93 73.95 5.15
MICD F 63.33 88.43 38.62 31.80 61.10 13.22 36.58 76.00 8.23
MICD D 66.97 89.24 45.05 33.24 57.89 17.61 39.87 78.46 12.11
ACD 67.82 90.16 45.83 35.37 62.17 18.38 41.47 82.90 11.68
Table 7: EM accuracy of full data (All) and subsets with gold context ( Subset Gold) and with noisy context
(Subset Noisy).
NQ TriviaQA PopQA
LLAMA 2-7B
RegOpn 45.13 68.12 33.47
CAD 29.22 48.91 25.97
MICD F51.07 72.37 36.81
MICD D72.92 86.33 56.04
ACD 76.72 88.79 54.58
LLAMA 2-13B
RegOpn 47.18 69.77 32.53
CAD 32.04 52.48 22.66
MICD F54.17 75.05 38.55
MICD D76.31 88.24 59.38
ACD 75.15 88.78 56.11
LLAMA 3-8B
RegOpn 46.20 68.50 33.39
CAD 32.91 50.51 23.00
MICD F43.25 70.67 39.07
MICD D61.18 83.70 59.80
ACD 64.14 86.59 56.87
MISTRAL -7B
RegOpn 41.04 64.57 31.03
CAD 19.17 42.63 20.80
MICD F48.12 71.99 36.48
MICD D69.58 86.84 57.14
ACD 70.62 89.36 53.55
Table 8: EM accuracy of Known-noisy case.NQ TriviaQA PopQA
LLAMA 2-7B
RegOpn 47.78 68.18 74.42
CAD 43.90 62.22 66.12
MICD F40.47 61.51 64.63
MICD D29.82 50.43 65.17
ACD 36.03 57.10 73.41
LLAMA 2-13B
RegOpn 46.52 65.09 75.04
CAD 45.77 61.07 69.43
MICD F41.79 62.03 65.85
MICD D30.72 47.77 64.70
ACD 36.19 53.98 72.38
LLAMA 3-8B
RegOpn 48.12 68.47 74.10
CAD 48.00 60.52 70.41
MICD F38.15 61.40 65.55
MICD D33.33 48.45 64.81
ACD 41.67 61.24 72.52
MISTRAL -7B
RegOpn 49.57 64.82 73.09
CAD 45.38 56.02 67.81
MICD F43.28 63.59 66.58
MICD D32.06 54.97 66.37
ACD 37.73 57.70 73.03
Table 9: EM accuracy of Unknown-gold case.
10

α NQ TriviaQA PopQA
LLAMA 2 7B
MaxMICD D52.77 60.09 61.84
ACD 69.24 75.31 74.12
Avg.MICD D57.86 62.00 71.79
ACD 71.61 73.41 77.92
FirstMICD D54.80 46.13 68.44
ACD 73.07 77.96 80.51
LLAMA 3 8B
MaxMICD D50.75 52.59 63.72
ACD 63.12 57.82 75.00
Avg.MICD D51.80 52.83 67.99
ACD 64.08 59.67 75.90
FirstMICD D45.70 39.07 69.21
ACD 67.48 75.45 80.31
MISTRAL 7B
MaxMICD D56.98 64.95 61.93
ACD 71.27 77.46 74.11
Avg.MICD D63.66 69.27 73.82
ACD 76.02 78.20 79.08
FirstMICD D56.84 68.98 71.73
ACD 75.75 84.11 82.07
Table 10: AUROC between αused in each method and
the noisiness of the retrieved context. The best AUROC
is in bold.
11

