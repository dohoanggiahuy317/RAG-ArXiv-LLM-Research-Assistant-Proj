id,link,title,abstract,authors,published
http://arxiv.org/abs/2408.01423v1,http://arxiv.org/abs/2408.01423v1,"Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM
  Auto-Prompting","Large Language Models (LLMs) exhibit remarkable proficiency in addressing a
diverse array of tasks within the Natural Language Processing (NLP) domain,
with various prompt design strategies significantly augmenting their
capabilities. However, these prompts, while beneficial, each possess inherent
limitations. The primary prompt design methodologies are twofold: The first,
exemplified by the Chain of Thought (CoT), involves manually crafting prompts
specific to individual datasets, hence termed Expert-Designed Prompts (EDPs).
Once these prompts are established, they are unalterable, and their
effectiveness is capped by the expertise of the human designers. When applied
to LLMs, the static nature of EDPs results in a uniform approach to both simple
and complex problems within the same dataset, leading to the inefficient use of
tokens for straightforward issues. The second method involves prompts
autonomously generated by the LLM, known as LLM-Derived Prompts (LDPs), which
provide tailored solutions to specific problems, mitigating the limitations of
EDPs. However, LDPs may encounter a decline in performance when tackling
complex problems due to the potential for error accumulation during the
solution planning process. To address these challenges, we have conceived a
novel Prompt Recursive Search (PRS) framework that leverages the LLM to
generate solutions specific to the problem, thereby conserving tokens. The
framework incorporates an assessment of problem complexity and an adjustable
structure, ensuring a reduction in the likelihood of errors. We have
substantiated the efficacy of PRS framework through extensive experiments using
LLMs with different numbers of parameters across a spectrum of datasets in
various domains. Compared to the CoT method, the PRS method has increased the
accuracy on the BBH dataset by 8% using Llama3-7B model, achieving a 22%
improvement.","[{'name': 'Xiangyu Zhao'}, {'name': 'Chengqian Ma'}]",2024-08-02T17:59:42Z
http://arxiv.org/abs/2408.01420v1,http://arxiv.org/abs/2408.01420v1,Mission Impossible: A Statistical Perspective on Jailbreaking LLMs,"Large language models (LLMs) are trained on a deluge of text data with
limited quality control. As a result, LLMs can exhibit unintended or even
harmful behaviours, such as leaking information, fake news or hate speech.
Countermeasures, commonly referred to as preference alignment, include
fine-tuning the pretrained LLMs with carefully crafted text examples of desired
behaviour. Even then, empirical evidence shows preference aligned LLMs can be
enticed to harmful behaviour. This so called jailbreaking of LLMs is typically
achieved by adversarially modifying the input prompt to the LLM. Our paper
provides theoretical insights into the phenomenon of preference alignment and
jailbreaking from a statistical perspective. Under our framework, we first show
that pretrained LLMs will mimic harmful behaviour if present in the training
corpus. Under that same framework, we then introduce a statistical notion of
alignment, and lower-bound the jailbreaking probability, showing that it is
unpreventable under reasonable assumptions. Based on our insights, we propose
an alteration to the currently prevalent alignment strategy RLHF. Specifically,
we introduce a simple modification to the RLHF objective, we call E-RLHF, that
aims to increase the likelihood of safe responses. E-RLHF brings no additional
training cost, and is compatible with other methods. Empirically, we
demonstrate that E-RLHF outperforms RLHF on all alignment problems put forward
by the AdvBench and HarmBench project without sacrificing model performance as
measured by the MT-Bench project.","[{'name': 'Jingtong Su'}, {'name': 'Julia Kempe'}, {'name': 'Karen Ullrich'}]",2024-08-02T17:55:50Z
http://arxiv.org/abs/2408.01419v1,http://arxiv.org/abs/2408.01419v1,DebateQA: Evaluating Question Answering on Debatable Knowledge,"The rise of large language models (LLMs) has enabled us to seek answers to
inherently debatable questions on LLM chatbots, necessitating a reliable way to
evaluate their ability. However, traditional QA benchmarks assume fixed answers
are inadequate for this purpose. To address this, we introduce DebateQA, a
dataset of 2,941 debatable questions, each accompanied by multiple
human-annotated partial answers that capture a variety of perspectives. We
develop two metrics: Perspective Diversity, which evaluates the
comprehensiveness of perspectives, and Dispute Awareness, which assesses if the
LLM acknowledges the question's debatable nature. Experiments demonstrate that
both metrics align with human preferences and are stable across different
underlying models. Using DebateQA with two metrics, we assess 12 popular LLMs
and retrieval-augmented generation methods. Our findings reveal that while LLMs
generally excel at recognizing debatable issues, their ability to provide
comprehensive answers encompassing diverse perspectives varies considerably.","[{'name': 'Rongwu Xu'}, {'name': 'Xuan Qi'}, {'name': 'Zehan Qi'}, {'name': 'Wei Xu'}, {'name': 'Zhijiang Guo'}]",2024-08-02T17:54:34Z
http://arxiv.org/abs/2408.01417v1,http://arxiv.org/abs/2408.01417v1,"Talk Less, Interact Better: Evaluating In-context Conversational
  Adaptation in Multimodal LLMs","Humans spontaneously use increasingly efficient language as interactions
progress, by adapting and forming ad-hoc conventions. This phenomenon has been
studied extensively using reference games, showing properties of human language
that go beyond relaying intents. It remains unexplored whether multimodal large
language models (MLLMs) similarly increase communication efficiency during
interactions, and what mechanisms they may adopt for this purpose. We introduce
ICCA, an automated framework to evaluate such conversational adaptation as an
in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and
observe that while they may understand the increasingly efficient language of
their interlocutor, they do not spontaneously make their own language more
efficient over time. This latter ability can only be elicited in some models
(e.g., GPT-4) with heavy-handed prompting. This shows that this property of
linguistic interaction does not arise from current training regimes, even
though it is a common hallmark of human language. ICCA is available at
https://github.com/lil-lab/ICCA.","[{'name': 'Yilun Hua'}, {'name': 'Yoav Artzi'}]",2024-08-02T17:51:57Z
http://arxiv.org/abs/2408.01402v1,http://arxiv.org/abs/2408.01402v1,"Pre-trained Language Models Improve the Few-shot Prompt Ability of
  Decision Transformer","Decision Transformer (DT) has emerged as a promising class of algorithms in
offline reinforcement learning (RL) tasks, leveraging pre-collected datasets
and Transformer's capability to model long sequences. Recent works have
demonstrated that using parts of trajectories from training tasks as prompts in
DT enhances its performance on unseen tasks, giving rise to Prompt-DT methods.
However, collecting data from specific environments can be both costly and
unsafe in many scenarios, leading to suboptimal performance and limited
few-shot prompt abilities due to the data-hungry nature of Transformer-based
models. Additionally, the limited datasets used in pre-training make it
challenging for Prompt-DT type of methods to distinguish between various RL
tasks through prompts alone. To address these challenges, we introduce the
Language model-initialized Prompt Decision Transformer (LPDT), which leverages
pre-trained language models for meta-RL tasks and fine-tunes the model using
Low-rank Adaptation (LoRA). We further incorporate prompt regularization to
effectively differentiate between tasks based on prompt feature
representations. Our approach integrates pre-trained language model and RL
tasks seamlessly. Extensive empirical studies demonstrate that initializing
with a pre-trained language model significantly enhances the performance of
Prompt-DT on unseen tasks compared to baseline methods.","[{'name': 'Yu Yang'}, {'name': 'Pan Xu'}]",2024-08-02T17:25:34Z
http://arxiv.org/abs/2408.01394v1,http://arxiv.org/abs/2408.01394v1,"Improving Multilingual Neural Machine Translation by Utilizing Semantic
  and Linguistic Features","The many-to-many multilingual neural machine translation can be regarded as
the process of integrating semantic features from the source sentences and
linguistic features from the target sentences. To enhance zero-shot
translation, models need to share knowledge across languages, which can be
achieved through auxiliary tasks for learning a universal representation or
cross-lingual mapping. To this end, we propose to exploit both semantic and
linguistic features between multiple languages to enhance multilingual
translation. On the encoder side, we introduce a disentangling learning task
that aligns encoder representations by disentangling semantic and linguistic
features, thus facilitating knowledge transfer while preserving complete
information. On the decoder side, we leverage a linguistic encoder to integrate
low-level linguistic features to assist in the target language generation.
Experimental results on multilingual datasets demonstrate significant
improvement in zero-shot translation compared to the baseline system, while
maintaining performance in supervised translation. Further analysis validates
the effectiveness of our method in leveraging both semantic and linguistic
features. The code is available at https://github.com/ictnlp/SemLing-MNMT.","[{'name': 'Mengyu Bu'}, {'name': 'Shuhao Gu'}, {'name': 'Yang Feng'}]",2024-08-02T17:10:12Z
http://arxiv.org/abs/2408.01380v1,http://arxiv.org/abs/2408.01380v1,Coalitions of Large Language Models Increase the Robustness of AI Agents,"The emergence of Large Language Models (LLMs) have fundamentally altered the
way we interact with digital systems and have led to the pursuit of LLM powered
AI agents to assist in daily workflows. LLMs, whilst powerful and capable of
demonstrating some emergent properties, are not logical reasoners and often
struggle to perform well at all sub-tasks carried out by an AI agent to plan
and execute a workflow. While existing studies tackle this lack of proficiency
by generalised pretraining at a huge scale or by specialised fine-tuning for
tool use, we assess if a system comprising of a coalition of pretrained LLMs,
each exhibiting specialised performance at individual sub-tasks, can match the
performance of single model agents. The coalition of models approach showcases
its potential for building robustness and reducing the operational costs of
these AI agents by leveraging traits exhibited by specific models. Our findings
demonstrate that fine-tuning can be mitigated by considering a coalition of
pretrained models and believe that this approach can be applied to other
non-agentic systems which utilise LLMs.","[{'name': 'Prattyush Mangal'}, {'name': 'Carol Mak'}, {'name': 'Theo Kanakis'}, {'name': 'Timothy Donovan'}, {'name': 'Dave Braines'}, {'name': 'Edward Pyzer-Knapp'}]",2024-08-02T16:37:44Z
http://arxiv.org/abs/2408.01367v1,http://arxiv.org/abs/2408.01367v1,Transformers are Universal In-context Learners,"Transformers are deep architectures that define ""in-context mappings"" which
enable predicting new tokens based on a given set of tokens (such as a prompt
in NLP applications or a set of patches for vision transformers). This work
studies in particular the ability of these architectures to handle an
arbitrarily large number of context tokens. To mathematically and uniformly
address the expressivity of these architectures, we consider the case that the
mappings are conditioned on a context represented by a probability distribution
of tokens (discrete for a finite number of tokens). The related notion of
smoothness corresponds to continuity in terms of the Wasserstein distance
between these contexts. We demonstrate that deep transformers are universal and
can approximate continuous in-context mappings to arbitrary precision,
uniformly over compact token domains. A key aspect of our results, compared to
existing findings, is that for a fixed precision, a single transformer can
operate on an arbitrary (even infinite) number of tokens. Additionally, it
operates with a fixed embedding dimension of tokens (this dimension does not
increase with precision) and a fixed number of heads (proportional to the
dimension). The use of MLP layers between multi-head attention layers is also
explicitly controlled.","[{'name': 'Takashi Furuya'}, {'name': 'Maarten V. de Hoop'}, {'name': 'Gabriel Peyré'}]",2024-08-02T16:21:48Z
http://arxiv.org/abs/2408.01363v1,http://arxiv.org/abs/2408.01363v1,"Toward Automatic Relevance Judgment using Vision--Language Models for
  Image--Text Retrieval Evaluation","Vision--Language Models (VLMs) have demonstrated success across diverse
applications, yet their potential to assist in relevance judgments remains
uncertain. This paper assesses the relevance estimation capabilities of VLMs,
including CLIP, LLaVA, and GPT-4V, within a large-scale \textit{ad hoc}
retrieval task tailored for multimedia content creation in a zero-shot fashion.
Preliminary experiments reveal the following: (1) Both LLaVA and GPT-4V,
encompassing open-source and closed-source visual-instruction-tuned Large
Language Models (LLMs), achieve notable Kendall's $\tau \sim 0.4$ when compared
to human relevance judgments, surpassing the CLIPScore metric. (2) While
CLIPScore is strongly preferred, LLMs are less biased towards CLIP-based
retrieval systems. (3) GPT-4V's score distribution aligns more closely with
human judgments than other models, achieving a Cohen's $\kappa$ value of around
0.08, which outperforms CLIPScore at approximately -0.096. These findings
underscore the potential of LLM-powered VLMs in enhancing relevance judgments.","[{'name': 'Jheng-Hong Yang'}, {'name': 'Jimmy Lin'}]",2024-08-02T16:15:25Z
http://arxiv.org/abs/2408.01346v1,http://arxiv.org/abs/2408.01346v1,"Prompt Refinement or Fine-tuning? Best Practices for using LLMs in
  Computational Social Science Tasks","Large Language Models are expressive tools that enable complex tasks of text
understanding within Computational Social Science. Their versatility, while
beneficial, poses a barrier for establishing standardized best practices within
the field. To bring clarity on the values of different strategies, we present
an overview of the performance of modern LLM-based classification methods on a
benchmark of 23 social knowledge tasks. Our results point to three best
practices: select models with larger vocabulary and pre-training corpora; avoid
simple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific
data, and consider more complex forms instruction-tuning on multiple datasets
only when only training data is more abundant.","[{'name': 'Anders Giovanni Møller'}, {'name': 'Luca Maria Aiello'}]",2024-08-02T15:46:36Z
http://arxiv.org/abs/2408.01337v1,http://arxiv.org/abs/2408.01337v1,"MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language
  Models","Multimodal models that jointly process audio and language hold great promise
in audio understanding and are increasingly being adopted in the music domain.
By allowing users to query via text and obtain information about a given audio
input, these models have the potential to enable a variety of music
understanding tasks via language-based interfaces. However, their evaluation
poses considerable challenges, and it remains unclear how to effectively assess
their ability to correctly interpret music-related inputs with current methods.
Motivated by this, we introduce MuChoMusic, a benchmark for evaluating music
understanding in multimodal language models focused on audio. MuChoMusic
comprises 1,187 multiple-choice questions, all validated by human annotators,
on 644 music tracks sourced from two publicly available music datasets, and
covering a wide variety of genres. Questions in the benchmark are crafted to
assess knowledge and reasoning abilities across several dimensions that cover
fundamental musical concepts and their relation to cultural and functional
contexts. Through the holistic analysis afforded by the benchmark, we evaluate
five open-source models and identify several pitfalls, including an
over-reliance on the language modality, pointing to a need for better
multimodal integration. Data and code are open-sourced.","[{'name': 'Benno Weck'}, {'name': 'Ilaria Manco'}, {'name': 'Emmanouil Benetos'}, {'name': 'Elio Quinton'}, {'name': 'George Fazekas'}, {'name': 'Dmitry Bogdanov'}]",2024-08-02T15:34:05Z
http://arxiv.org/abs/2408.01323v1,http://arxiv.org/abs/2408.01323v1,"FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs
  Only","Instruction fine-tuning stands as a crucial advancement in leveraging large
language models (LLMs) for enhanced task performance. However, the annotation
of instruction datasets has traditionally been expensive and laborious, often
relying on manual annotations or costly API calls of proprietary LLMs. To
address these challenges, we introduce FANNO, a fully autonomous, open-sourced
framework that revolutionizes the annotation process without the need for
pre-existing annotated data. Utilizing a Mistral-7b-instruct model, FANNO
efficiently produces diverse and high-quality datasets through a structured
process involving document pre-screening, instruction generation, and response
generation. Experiments on Open LLM Leaderboard and AlpacaEval benchmark show
that the FANNO can generate high-quality data with diversity and complexity for
free, comparable to human-annotated or cleaned datasets like
Alpaca-GPT4-Cleaned.","[{'name': 'He Zhu'}, {'name': 'Junyou Su'}, {'name': 'Tianle Lun'}, {'name': 'Yicheng Tao'}, {'name': 'Wenjia Zhang'}, {'name': 'Zipei Fan'}, {'name': 'Guanhua Chen'}]",2024-08-02T15:21:20Z
http://arxiv.org/abs/2408.01308v1,http://arxiv.org/abs/2408.01308v1,"Reconsidering Token Embeddings with the Definitions for Pre-trained
  Language Models","Learning token embeddings based on token co-occurrence statistics has proven
effective for both pre-training and fine-tuning in natural language processing.
However, recent studies have pointed out the distribution of learned embeddings
degenerates into anisotropy, and even pre-trained language models (PLMs) suffer
from a loss of semantics-related information in embeddings for low-frequency
tokens. This study first analyzes fine-tuning dynamics of a PLM, BART-large,
and demonstrates its robustness against degeneration. On the basis of this
finding, we propose DefinitionEMB, a method that utilizes definitions to
construct isotropically distributed and semantics-related token embeddings for
PLMs while maintaining original robustness during fine-tuning. Our experiments
demonstrate the effectiveness of leveraging definitions from Wiktionary to
construct such embeddings for RoBERTa-base and BART-large. Furthermore, the
constructed embeddings for low-frequency tokens improve the performance of
these models across various GLUE and four text summarization datasets.","[{'name': 'Ying Zhang'}, {'name': 'Dongyuan Li'}, {'name': 'Manabu Okumura'}]",2024-08-02T15:00:05Z
http://arxiv.org/abs/2408.01287v1,http://arxiv.org/abs/2408.01287v1,"Deep Learning based Visually Rich Document Content Understanding: A
  Survey","Visually Rich Documents (VRDs) are essential in academia, finance, medical
fields, and marketing due to their multimodal information content. Traditional
methods for extracting information from VRDs depend on expert knowledge and
manual labor, making them costly and inefficient. The advent of deep learning
has revolutionized this process, introducing models that leverage multimodal
information vision, text, and layout along with pretraining tasks to develop
comprehensive document representations. These models have achieved
state-of-the-art performance across various downstream tasks, significantly
enhancing the efficiency and accuracy of information extraction from VRDs. In
response to the growing demands and rapid developments in Visually Rich
Document Understanding (VRDU), this paper provides a comprehensive review of
deep learning-based VRDU frameworks. We systematically survey and analyze
existing methods and benchmark datasets, categorizing them based on adopted
strategies and downstream tasks. Furthermore, we compare different techniques
used in VRDU models, focusing on feature representation and fusion, model
architecture, and pretraining methods, while highlighting their strengths,
limitations, and appropriate scenarios. Finally, we identify emerging trends
and challenges in VRDU, offering insights into future research directions and
practical applications. This survey aims to provide a thorough understanding of
VRDU advancements, benefiting both academic and industrial sectors.","[{'name': 'Yihao Ding'}, {'name': 'Jean Lee'}, {'name': 'Soyeon Caren Han'}]",2024-08-02T14:19:34Z
http://arxiv.org/abs/2408.01285v1,http://arxiv.org/abs/2408.01285v1,"The Mismeasure of Man and Models: Evaluating Allocational Harms in Large
  Language Models","Large language models (LLMs) are now being considered and even deployed for
applications that support high-stakes decision-making, such as recruitment and
clinical decisions. While several methods have been proposed for measuring
bias, there remains a gap between predictions, which are what the proposed
methods consider, and how they are used to make decisions. In this work, we
introduce Rank-Allocational-Based Bias Index (RABBI), a model-agnostic bias
measure that assesses potential allocational harms arising from biases in LLM
predictions. We compare RABBI and current bias metrics on two allocation
decision tasks. We evaluate their predictive validity across ten LLMs and
utility for model selection. Our results reveal that commonly-used bias metrics
based on average performance gap and distribution distance fail to reliably
capture group disparities in allocation outcomes, whereas RABBI exhibits a
strong correlation with allocation disparities. Our work highlights the need to
account for how models are used in contexts with limited resource constraints.","[{'name': 'Hannah Chen'}, {'name': 'Yangfeng Ji'}, {'name': 'David Evans'}]",2024-08-02T14:13:06Z
http://arxiv.org/abs/2408.01262v1,http://arxiv.org/abs/2408.01262v1,RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework,"Retrieval-Augmented Generation (RAG) systems have demonstrated their
advantages in alleviating the hallucination of Large Language Models (LLMs).
Existing RAG benchmarks mainly focus on evaluating whether LLMs can correctly
answer the general knowledge. However, they are unable to evaluate the
effectiveness of the RAG system in dealing with the data from different
vertical domains. This paper introduces RAGEval, a framework for automatically
generating evaluation datasets to evaluate the knowledge usage ability of
different LLMs in different scenarios. Specifically, RAGEval summarizes a
schema from seed documents, applies the configurations to generate diverse
documents, and constructs question-answering pairs according to both articles
and configurations. We propose three novel metrics, Completeness,
Hallucination, and Irrelevance, to carefully evaluate the responses generated
by LLMs. By benchmarking RAG models in vertical domains, RAGEval has the
ability to better evaluate the knowledge usage ability of LLMs, which avoids
the confusion regarding the source of knowledge in answering question in
existing QA datasets--whether it comes from parameterized memory or retrieval.","[{'name': 'Kunlun Zhu'}, {'name': 'Yifan Luo'}, {'name': 'Dingling Xu'}, {'name': 'Ruobing Wang'}, {'name': 'Shi Yu'}, {'name': 'Shuo Wang'}, {'name': 'Yukun Yan'}, {'name': 'Zhenghao Liu'}, {'name': 'Xu Han'}, {'name': 'Zhiyuan Liu'}, {'name': 'Maosong Sun'}]",2024-08-02T13:35:11Z
http://arxiv.org/abs/2408.01214v1,http://arxiv.org/abs/2408.01214v1,High-Throughput Phenotyping of Clinical Text Using Large Language Models,"High-throughput phenotyping automates the mapping of patient signs to
standardized ontology concepts and is essential for precision medicine. This
study evaluates the automation of phenotyping of clinical summaries from the
Online Mendelian Inheritance in Man (OMIM) database using large language
models. Due to their rich phenotype data, these summaries can be surrogates for
physician notes. We conduct a performance comparison of GPT-4 and
GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in
identifying, categorizing, and normalizing signs, achieving concordance with
manual annotators comparable to inter-rater agreement. Despite some limitations
in sign normalization, the extensive pre-training of GPT-4 results in high
performance and generalizability across several phenotyping tasks while
obviating the need for manually annotated training data. Large language models
are expected to be the dominant method for automating high-throughput
phenotyping of clinical text.","[{'name': 'Daniel B. Hier'}, {'name': 'S. Ilyas Munzir'}, {'name': 'Anne Stahlfeld'}, {'name': 'Tayo Obafemi-Ajayi'}, {'name': 'Michael D. Carrithers'}]",2024-08-02T12:00:00Z
http://arxiv.org/abs/2408.01168v1,http://arxiv.org/abs/2408.01168v1,"Misinforming LLMs: vulnerabilities, challenges and opportunities","Large Language Models (LLMs) have made significant advances in natural
language processing, but their underlying mechanisms are often misunderstood.
Despite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely
on statistical patterns in word embeddings rather than true cognitive
processes. This leads to vulnerabilities such as ""hallucination"" and
misinformation. The paper argues that current LLM architectures are inherently
untrustworthy due to their reliance on correlations of sequential patterns of
word embedding vectors. However, ongoing research into combining generative
transformer-based models with fact bases and logic programming languages may
lead to the development of trustworthy LLMs capable of generating statements
based on given truth and explaining their self-reasoning process.","[{'name': 'Bo Zhou'}, {'name': 'Daniel Geißler'}, {'name': 'Paul Lukowicz'}]",2024-08-02T10:35:49Z
http://arxiv.org/abs/2408.01154v1,http://arxiv.org/abs/2408.01154v1,DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs,"Entity Alignment (EA) aims to match equivalent entities in different
Knowledge Graphs (KGs), which is essential for knowledge fusion and
integration. Recently, embedding-based EA has attracted significant attention
and many approaches have been proposed. Early approaches primarily focus on
learning entity embeddings from the structural features of KGs, defined by
relation triples. Later methods incorporated entities' names and attributes as
auxiliary information to enhance embeddings for EA. However, these approaches
often used different techniques to encode structural and attribute information,
limiting their interaction and mutual enhancement. In this work, we propose a
dense entity retrieval framework for EA, leveraging language models to
uniformly encode various features of entities and facilitate nearest entity
search across KGs. Alignment candidates are first generated through entity
retrieval, which are subsequently reranked to determine the final alignments.
We conduct comprehensive experiments on both cross-lingual and monolingual EA
datasets, demonstrating that our approach achieves state-of-the-art performance
compared to existing EA methods.","[{'name': 'Zhichun Wang'}, {'name': 'Xuan Chen'}]",2024-08-02T10:12:42Z
http://arxiv.org/abs/2408.01122v1,http://arxiv.org/abs/2408.01122v1,CFBench: A Comprehensive Constraints-Following Benchmark for LLMs,"The adeptness of Large Language Models (LLMs) in comprehending and following
natural language instructions is critical for their deployment in sophisticated
real-world applications. Existing evaluations mainly focus on fragmented
constraints or narrow scenarios, but they overlook the comprehensiveness and
authenticity of constraints from the user's perspective. To bridge this gap, we
propose CFBench, a large-scale Comprehensive Constraints Following Benchmark
for LLMs, featuring 1,000 curated samples that cover more than 200 real-life
scenarios and over 50 NLP tasks. CFBench meticulously compiles constraints from
real-world instructions and constructs an innovative systematic framework for
constraint types, which includes 10 primary categories and over 25
subcategories, and ensures each constraint is seamlessly integrated within the
instructions. To make certain that the evaluation of LLM outputs aligns with
user perceptions, we propose an advanced methodology that integrates
multi-dimensional assessment criteria with requirement prioritization, covering
various perspectives of constraints, instructions, and requirement fulfillment.
Evaluating current leading LLMs on CFBench reveals substantial room for
improvement in constraints following, and we further investigate influencing
factors and enhancement strategies. The data and code are publicly available at
https://github.com/PKU-Baichuan-MLSystemLab/CFBench","[{'name': 'Tao Zhang'}, {'name': 'Yanjun Shen'}, {'name': 'Wenjing Luo'}, {'name': 'Yan Zhang'}, {'name': 'Hao Liang'}, {'name': 'Tao Zhang'}, {'name': 'Fan Yang'}, {'name': 'Mingan Lin'}, {'name': 'Yujing Qiao'}, {'name': 'Weipeng Chen'}, {'name': 'Bin Cui'}, {'name': 'Wentao Zhang'}, {'name': 'Zenan Zhou'}]",2024-08-02T09:03:48Z
http://arxiv.org/abs/2408.01119v1,http://arxiv.org/abs/2408.01119v1,"Task Prompt Vectors: Effective Initialization through Multi-Task
  Soft-Prompt Transfer","Prompt tuning is a modular and efficient solution for training large language
models (LLMs). One of its main advantages is task modularity, making it
suitable for multi-task problems. However, current soft-prompt-based methods
often sacrifice multi-task modularity, requiring the training process to be
fully or partially repeated for each newly added task. While recent work on
task vectors applied arithmetic operations on full model weights to achieve the
desired multi-task performance, a similar approach for soft-prompts is still
missing. To this end, we introduce Task Prompt Vectors, created by element-wise
difference between weights of tuned soft-prompts and their random
initialization. Experimental results on 12 NLU datasets show that task prompt
vectors can be used in low-resource settings to effectively initialize prompt
tuning on similar tasks. In addition, we show that task prompt vectors are
independent of the random initialization of prompt tuning. This allows prompt
arithmetics with the pre-trained vectors from different tasks. In this way, by
arithmetic addition of task prompt vectors from multiple tasks, we are able to
outperform a state-of-the-art baseline in some cases.","[{'name': 'Robert Belanec'}, {'name': 'Simon Ostermann'}, {'name': 'Ivan Srba'}, {'name': 'Maria Bielikova'}]",2024-08-02T09:00:03Z
http://arxiv.org/abs/2408.01118v1,http://arxiv.org/abs/2408.01118v1,"IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation
  for Checkworthy Claim Detection","This paper describes IAI group's participation for automated check-worthiness
estimation for claims, within the framework of the 2024 CheckThat! Lab ""Task 1:
Check-Worthiness Estimation"". The task involves the automated detection of
check-worthy claims in English, Dutch, and Arabic political debates and Twitter
data. We utilized various pre-trained generative decoder and encoder
transformer models, employing methods such as few-shot chain-of-thought
reasoning, fine-tuning, data augmentation, and transfer learning from one
language to another. Despite variable success in terms of performance, our
models achieved notable placements on the organizer's leaderboard: ninth-best
in English, third-best in Dutch, and the top placement in Arabic, utilizing
multilingual datasets for enhancing the generalizability of check-worthiness
detection. Despite a significant drop in performance on the unlabeled test
dataset compared to the development test dataset, our findings contribute to
the ongoing efforts in claim detection research, highlighting the challenges
and potential of language-specific adaptations in claim verification systems.","[{'name': 'Peter Røysland Aarnes'}, {'name': 'Vinay Setty'}, {'name': 'Petra Galuščáková'}]",2024-08-02T08:59:09Z
http://arxiv.org/abs/2408.01107v1,http://arxiv.org/abs/2408.01107v1,BioRAG: A RAG-LLM Framework for Biological Question Reasoning,"The question-answering system for Life science research, which is
characterized by the rapid pace of discovery, evolving insights, and complex
interactions among knowledge entities, presents unique challenges in
maintaining a comprehensive knowledge warehouse and accurate information
retrieval. To address these issues, we introduce BioRAG, a novel
Retrieval-Augmented Generation (RAG) with the Large Language Models (LLMs)
framework. Our approach starts with parsing, indexing, and segmenting an
extensive collection of 22 million scientific papers as the basic knowledge,
followed by training a specialized embedding model tailored to this domain.
Additionally, we enhance the vector retrieval process by incorporating a
domain-specific knowledge hierarchy, which aids in modeling the intricate
interrelationships among each query and context. For queries requiring the most
current information, BioRAG deconstructs the question and employs an iterative
retrieval process incorporated with the search engine for step-by-step
reasoning. Rigorous experiments have demonstrated that our model outperforms
fine-tuned LLM, LLM with search engines, and other scientific RAG frameworks
across multiple life science question-answering tasks.","[{'name': 'Chengrui Wang'}, {'name': 'Qingqing Long'}, {'name': 'Xiao Meng'}, {'name': 'Xunxin Cai'}, {'name': 'Chengjun Wu'}, {'name': 'Zhen Meng'}, {'name': 'Xuezhi Wang'}, {'name': 'Yuanchun Zhou'}]",2024-08-02T08:37:03Z
http://arxiv.org/abs/2408.01090v1,http://arxiv.org/abs/2408.01090v1,General-purpose Dataflow Model with Neuromorphic Primitives,"Neuromorphic computing exhibits great potential to provide high-performance
benefits in various applications beyond neural networks. However, a
general-purpose program execution model that aligns with the features of
neuromorphic computing is required to bridge the gap between program
versatility and neuromorphic hardware efficiency. The dataflow model offers a
potential solution, but it faces high graph complexity and incompatibility with
neuromorphic hardware when dealing with control flow programs, which decreases
the programmability and performance. Here, we present a dataflow model tailored
for neuromorphic hardware, called neuromorphic dataflow, which provides a
compact, concise, and neuromorphic-compatible program representation for
control logic. The neuromorphic dataflow introduces ""when"" and ""where""
primitives, which restructure the view of control. The neuromorphic dataflow
embeds these primitives in the dataflow schema with the plasticity inherited
from the spiking algorithms. Our method enables the deployment of
general-purpose programs on neuromorphic hardware with both programmability and
plasticity, while fully utilizing the hardware's potential.","[{'name': 'Weihao Zhang'}, {'name': 'Yu Du'}, {'name': 'Hongyi Li'}, {'name': 'Songchen Ma'}, {'name': 'Rong Zhao'}]",2024-08-02T08:09:13Z
http://arxiv.org/abs/2408.01088v1,http://arxiv.org/abs/2408.01088v1,"Bridging Information Gaps in Dialogues With Grounded Exchanges Using
  Knowledge Graphs","Knowledge models are fundamental to dialogue systems for enabling
conversational interactions, which require handling domain-specific knowledge.
Ensuring effective communication in information-providing conversations entails
aligning user understanding with the knowledge available to the system.
However, dialogue systems often face challenges arising from semantic
inconsistencies in how information is expressed in natural language compared to
how it is represented within the system's internal knowledge. To address this
problem, we study the potential of large language models for conversational
grounding, a mechanism to bridge information gaps by establishing shared
knowledge between dialogue participants. Our approach involves annotating human
conversations across five knowledge domains to create a new dialogue corpus
called BridgeKG. Through a series of experiments on this dataset, we
empirically evaluate the capabilities of large language models in classifying
grounding acts and identifying grounded information items within a knowledge
graph structure. Our findings offer insights into how these models use
in-context learning for conversational grounding tasks and common prediction
errors, which we illustrate with examples from challenging dialogues. We
discuss how the models handle knowledge graphs as a semantic layer between
unstructured dialogue utterances and structured information items.","[{'name': 'Phillip Schneider'}, {'name': 'Nektarios Machner'}, {'name': 'Kristiina Jokinen'}, {'name': 'Florian Matthes'}]",2024-08-02T08:07:15Z
http://arxiv.org/abs/2408.01084v1,http://arxiv.org/abs/2408.01084v1,"Adaptive Contrastive Decoding in Retrieval-Augmented Generation for
  Handling Noisy Contexts","When using large language models (LLMs) in knowledge-intensive tasks, such as
open-domain question answering, external context can bridge a gap between
external knowledge and LLM's parametric knowledge. Recent research has been
developed to amplify contextual knowledge over the parametric knowledge of LLM
with contrastive decoding approaches. While these approaches could yield
truthful responses when relevant context is provided, they are prone to
vulnerabilities when faced with noisy contexts. We extend the scope of previous
studies to encompass noisy contexts and propose adaptive contrastive decoding
(ACD) to leverage contextual influence effectively. ACD demonstrates
improvements in open-domain question answering tasks compared to baselines,
especially in robustness by remaining undistracted by noisy contexts in
retrieval-augmented generation.","[{'name': 'Youna Kim'}, {'name': 'Hyuhng Joon Kim'}, {'name': 'Cheonbok Park'}, {'name': 'Choonghyun Park'}, {'name': 'Hyunsoo Cho'}, {'name': 'Junyeob Kim'}, {'name': 'Kang Min Yoo'}, {'name': 'Sang-goo Lee'}, {'name': 'Taeuk Kim'}]",2024-08-02T08:03:38Z
http://arxiv.org/abs/2408.01063v1,http://arxiv.org/abs/2408.01063v1,"Leveraging Large Language Models for Mobile App Review Feature
  Extraction","Mobile app review analysis presents unique challenges due to the low quality,
subjective bias, and noisy content of user-generated documents. Extracting
features from these reviews is essential for tasks such as feature
prioritization and sentiment analysis, but it remains a challenging task.
Meanwhile, encoder-only models based on the Transformer architecture have shown
promising results for classification and information extraction tasks for
multiple software engineering processes. This study explores the hypothesis
that encoder-only large language models can enhance feature extraction from
mobile app reviews. By leveraging crowdsourced annotations from an industrial
context, we redefine feature extraction as a supervised token classification
task. Our approach includes extending the pre-training of these models with a
large corpus of user reviews to improve contextual understanding and employing
instance selection techniques to optimize model fine-tuning. Empirical
evaluations demonstrate that this method improves the precision and recall of
extracted features and enhances performance efficiency. Key contributions
include a novel approach to feature extraction, annotated datasets, extended
pre-trained models, and an instance selection mechanism for cost-effective
fine-tuning. This research provides practical methods and empirical evidence in
applying large language models to natural language processing tasks within
mobile app reviews, offering improved performance in feature extraction.","[{'name': 'Quim Motger'}, {'name': 'Alessio Miaschi'}, {'name': ""Felice Dell'Orletta""}, {'name': 'Xavier Franch'}, {'name': 'Jordi Marco'}]",2024-08-02T07:31:57Z
http://arxiv.org/abs/2408.01050v1,http://arxiv.org/abs/2408.01050v1,"The Impact of Hyperparameters on Large Language Model Inference
  Performance: An Evaluation of vLLM and HuggingFace Pipelines","The recent surge of open-source large language models (LLMs) enables
developers to create AI-based solutions while maintaining control over aspects
such as privacy and compliance, thereby providing governance and ownership of
the model deployment process. To utilize these LLMs, inference engines are
needed. These engines load the model's weights onto available resources, such
as GPUs, and process queries to generate responses. The speed of inference, or
performance, of the LLM, is critical for real-time applications, as it computes
millions or billions of floating point operations per inference. Recently,
advanced inference engines such as vLLM have emerged, incorporating novel
mechanisms such as efficient memory management to achieve state-of-the-art
performance. In this paper, we analyze the performance, particularly the
throughput (tokens generated per unit of time), of 20 LLMs using two inference
libraries: vLLM and HuggingFace's pipelines. We investigate how various
hyperparameters, which developers must configure, influence inference
performance. Our results reveal that throughput landscapes are irregular, with
distinct peaks, highlighting the importance of hyperparameter optimization to
achieve maximum performance. We also show that applying hyperparameter
optimization when upgrading or downgrading the GPU model used for inference can
improve throughput from HuggingFace pipelines by an average of 9.16% and 13.7%,
respectively.",[{'name': 'Matias Martinez'}],2024-08-02T06:56:59Z
http://arxiv.org/abs/2408.01046v1,http://arxiv.org/abs/2408.01046v1,QUDSELECT: Selective Decoding for Questions Under Discussion Parsing,"Question Under Discussion (QUD) is a discourse framework that uses implicit
questions to reveal discourse relationships between sentences. In QUD parsing,
each sentence is viewed as an answer to a question triggered by an anchor
sentence in prior context. The resulting QUD structure is required to conform
to several theoretical criteria like answer compatibility (how well the
question is answered), making QUD parsing a challenging task. Previous works
construct QUD parsers in a pipelined manner (i.e. detect the trigger sentence
in context and then generate the question). However, these parsers lack a
holistic view of the task and can hardly satisfy all the criteria. In this
work, we introduce QUDSELECT, a joint-training framework that selectively
decodes the QUD dependency structures considering the QUD criteria. Using
instruction-tuning, we train models to simultaneously predict the anchor
sentence and generate the associated question. To explicitly incorporate the
criteria, we adopt a selective decoding strategy of sampling multiple QUD
candidates during inference, followed by selecting the best one with criteria
scorers. Our method outperforms the state-of-the-art baseline models by 9% in
human evaluation and 4% in automatic evaluation, demonstrating the
effectiveness of our framework.","[{'name': 'Ashima Suvarna'}, {'name': 'Xiao Liu'}, {'name': 'Tanmay Parekh'}, {'name': 'Kai-Wei Chang'}, {'name': 'Nanyun Peng'}]",2024-08-02T06:46:08Z
http://arxiv.org/abs/2408.01038v1,http://arxiv.org/abs/2408.01038v1,"UNER: A Unified Prediction Head for Named Entity Recognition in
  Visually-rich Documents","The recognition of named entities in visually-rich documents (VrD-NER) plays
a critical role in various real-world scenarios and applications. However, the
research in VrD-NER faces three major challenges: complex document layouts,
incorrect reading orders, and unsuitable task formulations. To address these
challenges, we propose a query-aware entity extraction head, namely UNER, to
collaborate with existing multi-modal document transformers to develop more
robust VrD-NER models. The UNER head considers the VrD-NER task as a
combination of sequence labeling and reading order prediction, effectively
addressing the issues of discontinuous entities in documents. Experimental
evaluations on diverse datasets demonstrate the effectiveness of UNER in
improving entity extraction performance. Moreover, the UNER head enables a
supervised pre-training stage on various VrD-NER datasets to enhance the
document transformer backbones and exhibits substantial knowledge transfer from
the pre-training stage to the fine-tuning stage. By incorporating universal
layout understanding, a pre-trained UNER-based model demonstrates significant
advantages in few-shot and cross-linguistic scenarios and exhibits zero-shot
entity extraction abilities.","[{'name': 'Yi Tu'}, {'name': 'Chong Zhang'}, {'name': 'Ya Guo'}, {'name': 'Huan Chen'}, {'name': 'Jinyang Tang'}, {'name': 'Huijia Zhu'}, {'name': 'Qi Zhang'}]",2024-08-02T06:21:36Z
